{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FourierGNN prediction model - capstone analysis\n",
    "\n",
    "FourierGNN https://github.com/aikunyi/FourierGNN\n",
    "\n",
    "I have forked the FourierGNN and made some minor modifications to adapt it for our use case. Moreover, some of the functions from FourierGNN are used in the below notebook to support modelling.\n",
    "\n",
    "\n",
    "Uses FourierGNN to predict 1-step ahead values of the multivariate time series. \n",
    "\n",
    "A Fully Connected Neural Network is then used to predict the log returns value from the FourierGNN predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.utils import save_model, load_model, evaluate\n",
    "from data.data_loader import Dataset_Capstone\n",
    "from model.FourierGNN import FGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Prepare 2 datasets for use in FourierGNN model.\n",
    "- Dataset 1 includes 2xx features\n",
    "- Dataset 2 uses a selected set of features\n",
    "\n",
    "Input data has already been transformed towards stationarity through Yeo-Johnson and differencing. The dataset starts post COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filtered_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset on post-COVID period. \n",
    "\n",
    "The COVID period appeared to reduce model performance in testing. Given it is not expected to be representative of the models prediction regime, this model will only consider post-Covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing COVID spike\n",
    "df[['FACTSET_SP_500_Close']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index soon after COVID spike\n",
    "covid_idx = 370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evidencing that COVID spike is not present in the training data\n",
    "df[['FACTSET_SP_500_Close']][covid_idx:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating df to only contain data after COVID spike\n",
    "df = df[covid_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two testing datasets, one containing all available variables, and the other containing a reduced set of columns. The features selected for the subsequent dataset were chosen due to their high feature importances in an XGBoost model and a Lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select key features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_top_features = [\n",
    "    'FACTSET_P_PER_B_LTM',\n",
    "    'FACTSET_P_PER_CF_LTM',\n",
    "    'FACTSET_P_PER_E_LTM',\n",
    "    'MACROSYNERGY_IMPINFM1Y_NSA',\n",
    "    'FACTSET_EV_PER_EBITDA_LTM',\n",
    "    'FACTSET_P_PER_E_LTM.1',\n",
    "    'FACTSET_EV_PER_EBIT_LTM',\n",
    "    'FACTSET_P_PER_FFO_LTM',\n",
    "    'FACTSET_P_PER_Sales_LTM.1',\n",
    "    'FACTSET_SP_500_Market_Value',\n",
    "    'MACROSYNERGY_EQCUTLR_NSA',\n",
    "    'MACROSYNERGY_EQCRELR_NSA',\n",
    "    'MACROSYNERGY_IMPINFS1Y_NSA',\n",
    "    'MACROSYNERGY_EQXR_NSA',\n",
    "    'MACROSYNERGY_EQCMATR_NSA',\n",
    "    'MACROSYNERGY_CDS02YCRYHvGDRB_NSA',\n",
    "    'MACROSYNERGY_EQCFINR_NSA',\n",
    "    'MACROSYNERGY_EQCCSRR_NSA',\n",
    "    'MACROSYNERGY_GB03YYLD_NSA',\n",
    "    'MACROSYNERGY_GB10YYLD_NSA',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_top_features = [\n",
    "    'MACROSYNERGY_IMPINFS1Y_NSA',\n",
    "    'neutral',\n",
    "    'Initial Jobless Claims',\n",
    "    'MACROSYNERGY_CDS02YCRY_VT10',\n",
    "    'MACROSYNERGY_IMPINFM1Y_NSA',\n",
    "    'FACTSET_EV_PER_EBITDA_LTM',\n",
    "    'FACTSET_P_PER_Sales_LTM',\n",
    "    'FACTSET_SP_500_Market_Value',\n",
    "    'MACROSYNERGY_CDS02YSPRD_NSA',\n",
    "    'score',\n",
    "    'MACROSYNERGY_GB30YYLD_NSA',\n",
    "    'MACROSYNERGY_CDS02YCRY_NSA',\n",
    "    'FACTSET_SP_500_ROE_LTM',\n",
    "    'MACROSYNERGY_GGDGDPRATIOX10_NSA',\n",
    "    'FACTSET_SP_500_Net_Inc',\n",
    "    'FACTSET_SP_500_EPS_LTM',\n",
    "    'FACTSET_SP_500_Net_Margin_LTM',\n",
    "    'FACTSET_SP_500_Pretax_Margin_LTM',\n",
    "    'FACTSET_SP_500_BV_LTM',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_target = ['FACTSET_SP_500_Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = curr_target + list(set(lasso_top_features + xgb_top_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[selected_features].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot key features to visually check for stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in selected_features:\n",
    "    df[feature].plot()\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FourierGNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataclass containing attributes for each model run specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass \n",
    "class ModelConfig:\n",
    "    seq_len: int\n",
    "    train_ratio: float\n",
    "    val_ratio:float\n",
    "    pre_len: int\n",
    "    type: int\n",
    "    embed_size: int\n",
    "    hidden_size: int\n",
    "    learning_rate: float\n",
    "    n_epochs: int\n",
    "    exponential_decay_step: int\n",
    "    decay_rate: float \n",
    "    feature_size: int\n",
    "    dataset: pd.DataFrame\n",
    "    target_idx: int\n",
    "    label: str\n",
    "    batch_size: int\n",
    "    validate_freq: int\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing variety of configurations to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = []\n",
    "\n",
    "for df in [df_1, df_2]:\n",
    "    for seq_len in [7, 31, 62]:\n",
    "        for embed_size, hidden_size in zip([128, 256, 512], [256, 512, 1024]):\n",
    "            for learning_rate in [0.0001, 0.00001, 0.000001]:\n",
    "                model_configs.append(\n",
    "                    ModelConfig(\n",
    "                        seq_len=seq_len, \n",
    "                        train_ratio=0.8, \n",
    "                        val_ratio=0.1, \n",
    "                        pre_len=1, \n",
    "                        type=0, \n",
    "                        embed_size=embed_size, \n",
    "                        hidden_size=hidden_size, \n",
    "                        learning_rate=learning_rate, \n",
    "                        n_epochs=40, \n",
    "                        exponential_decay_step=5, \n",
    "                        decay_rate=0.1, \n",
    "                        feature_size=len(df.columns), \n",
    "                        dataset=df, \n",
    "                        target_idx=0,\n",
    "                        label=f'FGN_model_{len(df.columns)}_{seq_len}_{embed_size}_{learning_rate}',\n",
    "                        batch_size=32,\n",
    "                        validatate_freq=1\n",
    "                    )\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to train FourierGNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from from https://github.com/aikunyi/FourierGNN\n",
    "def validate(model, vali_loader, device, forecast_loss):\n",
    "    model.eval()\n",
    "    cnt = 0\n",
    "    loss_total = 0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for i, (x, y) in enumerate(vali_loader):\n",
    "        cnt += 1\n",
    "        y = y.float().to(device)\n",
    "        x = x.float().to(device)\n",
    "        forecast = torch.squeeze(model(x))\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        loss = forecast_loss(forecast, y)\n",
    "        loss_total += float(loss)\n",
    "        forecast = forecast.detach().cpu().numpy()\n",
    "        y = y.detach().cpu().numpy()\n",
    "        preds.append(forecast)\n",
    "        trues.append(y)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    trues = np.concatenate(trues, axis=0)\n",
    "    score = evaluate(trues, preds)\n",
    "    print(f'RAW : MAPE {score[0]:7.9%}; MAE {score[1]:7.9f}; RMSE {score[2]:7.9f}.')\n",
    "    model.train()\n",
    "    return loss_total/cnt\n",
    "\n",
    "# Training code heavily borrows from https://github.com/aikunyi/FourierGNN\n",
    "def train_model(model_config: ModelConfig):\n",
    "    \n",
    "    # Prepare training dataset\n",
    "    train_dataset = Dataset_Capstone(\n",
    "        data=model_config.dataset, \n",
    "        flag='train', \n",
    "        seq_len=model_config.seq_length, \n",
    "        pre_len=model_config.pre_length, \n",
    "        type=model_config.type, \n",
    "        train_ratio=model_config.train_ratio, \n",
    "        val_ratio=model_config.val_ratio\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=model_config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # Prepare validation dataset\n",
    "    val_dataset = Dataset_Capstone(\n",
    "        data=model_config.dataset, \n",
    "        flag='val', \n",
    "        seq_len=model_config.seq_length, \n",
    "        pre_len=model_config.pre_length, \n",
    "        type=model_config.type, \n",
    "        train_ratio=model_config.train_ratio, \n",
    "        val_ratio=model_config.val_ratio\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=model_config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # Prepare FourierGNN model\n",
    "    model = FGN(\n",
    "        pre_length=model_config.pre_length, \n",
    "        embed_size=model_config.embed_size, \n",
    "        feature_size=model_config.feature_size, \n",
    "        seq_length=model_config.seq_length, \n",
    "        hidden_size=model_config.hidden_size\n",
    "    )\n",
    "\n",
    "    # Prepare optimizer and loss function\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    my_optim = torch.optim.RMSprop(params=model.parameters(), lr=model_config.learning_rate, eps=1e-08)\n",
    "    my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=my_optim, gamma=model_config.decay_rate)\n",
    "    forecast_loss = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "    # Train model\n",
    "    for epoch in range(model_config.n_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        loss_total = 0\n",
    "        cnt = 0\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for index, (x, y) in enumerate(train_dataloader):\n",
    "            cnt += 1\n",
    "            y = y.float().to(device)\n",
    "            x = x.float().to(device)\n",
    "            forecast = model(x)\n",
    "            y = y.permute(0, 2, 1).contiguous()\n",
    "            loss = forecast_loss(forecast, y)\n",
    "            loss.backward()\n",
    "            my_optim.step()\n",
    "            loss_total += float(loss)\n",
    "            train_losses.append(float(loss))\n",
    "\n",
    "        if (epoch + 1) % model_config.exponential_decay_step == 0:\n",
    "            my_lr_scheduler.step()\n",
    "        if (epoch + 1) % model_config.validate_freq == 0:\n",
    "            val_loss = validate(model, val_dataloader, device, forecast_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | train_total_loss {:5.4f} | val_loss {:5.4f}'.format(\n",
    "                epoch, (time.time() - epoch_start_time), loss_total / cnt, val_loss))\n",
    "        \n",
    "    # Plot loss curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='train_loss')\n",
    "    plt.plot(val_losses, label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(model_config.label)\n",
    "    plt.show()\n",
    "\n",
    "    # Save model\n",
    "    with open(f'models/{model_config.label}', 'wb') as f:\n",
    "        torch.save(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in model_configs:\n",
    "    train_model(config)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_predictions(model_config: ModelConfig):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    with open(f'models/{model_config.label}', 'rb') as f:\n",
    "        model = torch.load(f)\n",
    "\n",
    "    for label in ['train', 'val', 'test']:\n",
    "\n",
    "        dataset = Dataset_Capstone(\n",
    "            data=model_config.dataset, \n",
    "            flag=label, \n",
    "            seq_len=model_config.seq_length, \n",
    "            pre_len=model_config.pre_length, \n",
    "            type=model_config.type, \n",
    "            train_ratio=model_config.train_ratio, \n",
    "            val_ratio=model_config.val_ratio\n",
    "        )\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=model_config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        trues = []\n",
    "        for index, (x, y) in enumerate(dataloader):\n",
    "            y = y.float().to(device)\n",
    "            x = x.float().to(device)\n",
    "            forecast = model(x)\n",
    "            y = y.permute(0, 2, 1).contiguous()\n",
    "            forecast = forecast.detach().cpu().numpy()\n",
    "            y = y.detach().cpu().numpy()\n",
    "            preds.append(forecast)\n",
    "            trues.append(y)\n",
    "\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        trues = np.concatenate(trues, axis=0)\n",
    "\n",
    "        # Compute performance metrics\n",
    "        mse = np.mean((preds - trues) ** 2)\n",
    "        directionally_correct = np.mean(np.sign(preds) == np.sign(trues))\n",
    "\n",
    "        # Plot predictions\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(preds.T[model_config.target_idx], label='Predictions')\n",
    "        plt.plot(trues.T[model_config.target_idx], label='Actual')\n",
    "        plt.title(f'{model_config.label} {label} : MSE {mse} : Directionally correct {directionally_correct}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data for Fully Connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_y_train = fgnn_trues_train.T[0][0].reshape(-1, 1)\n",
    "fc_X_train = fgnn_preds_train.T[0][:].squeeze().T\n",
    "fc_X_train = np.concatenate([fc_X_train[1:], fc_y_train[:-1]], axis=1)\n",
    "fc_y_train = fc_y_train[1:]\n",
    "print(f'fc_X_train.shape: {fc_X_train.shape}, fc_y_train.shape: {fc_y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_fc_X_train = torch.Tensor(fc_X_train)\n",
    "tensor_fc_y_train = torch.Tensor(fc_y_train)\n",
    "\n",
    "fc_train_dataset = TensorDataset(tensor_fc_X_train, tensor_fc_y_train)\n",
    "fc_train_dataloader = DataLoader(fc_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify Fully Connected NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(37, 120)\n",
    "        self.d1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.d2 = nn.Dropout(p=0.2)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fc4 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.d1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.d2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = FCNN()\n",
    "fc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train FCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_criterion = nn.MSELoss()\n",
    "fc_learning_rate = 0.000001\n",
    "fc_optimizer = optim.Adam(fc_model.parameters(), lr=fc_learning_rate)\n",
    "fc_n_epochs = 100\n",
    "\n",
    "for fc_epoch in range(fc_n_epochs):\n",
    "    fc_running_loss = 0.0\n",
    "    for i, data in enumerate(fc_train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        fc_optimizer.zero_grad()\n",
    "        outputs = fc_model(inputs)\n",
    "        loss = fc_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        fc_optimizer.step()\n",
    "\n",
    "        fc_running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print(f'[{fc_epoch + 1}, {i + 1:5d}] loss: {fc_running_loss / 200:}')\n",
    "            fc_running_loss = 0.0\n",
    "\n",
    "save_model(fc_model, 'output/capstone/fcnn/train', fc_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_y_val = fgnn_trues_val.T[0][0].reshape(-1, 1)\n",
    "fc_X_val = fgnn_preds_val.T[0][:].squeeze().T\n",
    "fc_X_val = np.concatenate([fc_X_val[1:], fc_y_val[:-1]], axis=1)\n",
    "fc_y_val = fc_y_val[1:]\n",
    "print(f'fc_X_val.shape: {fc_X_val.shape}, fc_y_val.shape: {fc_y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_fc_X_val = torch.Tensor(fc_X_val)\n",
    "tensor_fc_y_val = torch.Tensor(fc_y_val)\n",
    "\n",
    "fc_val_dataset = TensorDataset(tensor_fc_X_val, tensor_fc_y_val)\n",
    "fc_val_dataloader = DataLoader(fc_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the FCNN model version to use for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model_ver = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict using FCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnn_model_path = 'output/capstone/fcnn/train'\n",
    "fcnn_model = load_model(fcnn_model_path, fc_model_ver)\n",
    "fcnn_model.eval()\n",
    "fcnn_preds_val = []\n",
    "fcnn_trues_val = []\n",
    "for index, (x, y) in enumerate(fc_val_dataloader):\n",
    "    y = y.float().to(device)\n",
    "    x = x.float().to(device)\n",
    "    fcnn_forecast_val = fcnn_model(x)\n",
    "    fcnn_forecast_val = fcnn_forecast_val.detach().cpu().numpy()\n",
    "    y = y.detach().cpu().numpy()\n",
    "    fcnn_preds_val.append(fcnn_forecast_val)\n",
    "    fcnn_trues_val.append(y)\n",
    "\n",
    "fcnn_preds_val = np.concatenate(fcnn_preds_val, axis=0)\n",
    "fcnn_trues_val = np.concatenate(fcnn_trues_val, axis=0)\n",
    "fcnn_score_val = evaluate(fcnn_trues_val, fcnn_preds_val)\n",
    "print(f'RAW : MAPE {fcnn_score_val[0]:7.9%}; MAE {fcnn_score_val[1]:7.9f}; RMSE {fcnn_score_val[2]:7.9f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "mse = np.mean((fcnn_preds_val - fcnn_trues_val)**2)\n",
    "direction = np.sign(fcnn_preds_val) == np.sign(fcnn_trues_val)\n",
    "direction_perc = np.sum(direction) / len(direction)\n",
    "\n",
    "plt.plot(fcnn_preds_val, label='FCNN preds')\n",
    "plt.plot(fcnn_trues_val, label='Actual')\n",
    "plt.title(f'FGNN + FCNN predictions : MSE {mse:.6f} : Directionally correct {direction_perc:.1%}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare test data for FCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_y_test = fgnn_trues_test.T[-1][0].reshape(-1, 1)\n",
    "fc_X_test = fgnn_preds_test.T[-1][:].squeeze().T\n",
    "fc_X_test = np.concatenate([fc_X_test[1:], fc_y_test[:-1]], axis=1)\n",
    "fc_y_test = fc_y_test[1:]\n",
    "print(f'fc_X_test.shape: {fc_X_test.shape}, fc_y_test.shape: {fc_y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_fc_X_test = torch.Tensor(fc_X_test)\n",
    "tensor_fc_y_test = torch.Tensor(fc_y_test)\n",
    "\n",
    "fc_test_dataset = TensorDataset(tensor_fc_X_test, tensor_fc_y_test)\n",
    "fc_test_dataloader = DataLoader(fc_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the FCNN version to use for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model_ver = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict using FCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnn_model_path = 'output/capstone/fcnn/train'\n",
    "fcnn_model = load_model(fcnn_model_path, fc_model_ver)\n",
    "fcnn_model.eval()\n",
    "fcnn_preds_test = []\n",
    "fcnn_trues_test = []\n",
    "for index, (x, y) in enumerate(fc_test_dataloader):\n",
    "    y = y.float().to(device)\n",
    "    x = x.float().to(device)\n",
    "    fcnn_forecast_test = fcnn_model(x)\n",
    "    fcnn_forecast_test = fcnn_forecast_test.detach().cpu().numpy()\n",
    "    y = y.detach().cpu().numpy()\n",
    "    fcnn_preds_test.append(fcnn_forecast_test)\n",
    "    fcnn_trues_test.append(y)\n",
    "\n",
    "fcnn_preds_test = np.concatenate(fcnn_preds_test, axis=0)\n",
    "fcnn_trues_test = np.concatenate(fcnn_trues_test, axis=0)\n",
    "fcnn_score_test = evaluate(fcnn_trues_test, fcnn_preds_test)\n",
    "print(f'RAW : MAPE {fcnn_score_test[0]:7.9%}; MAE {fcnn_score_test[1]:7.9f}; RMSE {fcnn_score_test[2]:7.9f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e104",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
